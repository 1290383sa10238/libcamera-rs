//! Generated by `cargo run --bin generate_rust controls`

use crate::{Control, ControlValueError};

pub enum ControlId {
    /// Enable or disable the AE.
    /// 
    /// \sa ExposureTime AnalogueGain
    AeEnable = 1,
    /// Report the lock status of a running AE algorithm.
    /// 
    /// If the AE algorithm is locked the value shall be set to true, if it's
    /// converging it shall be set to false. If the AE algorithm is not
    /// running the control shall not be present in the metadata control list.
    /// 
    /// \sa AeEnable
    AeLocked = 2,
    /// Specify a metering mode for the AE algorithm to use. The metering
    /// modes determine which parts of the image are used to determine the
    /// scene brightness. Metering modes may be platform specific and not
    /// all metering modes may be supported.
    AeMeteringMode = 3,
    /// Specify a constraint mode for the AE algorithm to use. These determine
    /// how the measured scene brightness is adjusted to reach the desired
    /// target exposure. Constraint modes may be platform specific, and not
    /// all constraint modes may be supported.
    AeConstraintMode = 4,
    /// Specify an exposure mode for the AE algorithm to use. These specify
    /// how the desired total exposure is divided between the shutter time
    /// and the sensor's analogue gain. The exposure modes are platform
    /// specific, and not all exposure modes may be supported.
    AeExposureMode = 5,
    /// Specify an Exposure Value (EV) parameter. The EV parameter will only be
    /// applied if the AE algorithm is currently enabled.
    /// 
    /// By convention EV adjusts the exposure as log2. For example
    /// EV = [-2, -1, 0.5, 0, 0.5, 1, 2] results in an exposure adjustment
    /// of [1/4x, 1/2x, 1/sqrt(2)x, 1x, sqrt(2)x, 2x, 4x].
    /// 
    /// \sa AeEnable
    ExposureValue = 6,
    /// Exposure time (shutter speed) for the frame applied in the sensor
    /// device. This value is specified in micro-seconds.
    /// 
    /// Setting this value means that it is now fixed and the AE algorithm may
    /// not change it. Setting it back to zero returns it to the control of the
    /// AE algorithm.
    /// 
    /// \sa AnalogueGain AeEnable
    /// 
    /// \todo Document the interactions between AeEnable and setting a fixed
    /// value for this control. Consider interactions with other AE features,
    /// such as aperture and aperture/shutter priority mode, and decide if
    /// control of which features should be automatically adjusted shouldn't
    /// better be handled through a separate AE mode control.
    ExposureTime = 7,
    /// Analogue gain value applied in the sensor device.
    /// The value of the control specifies the gain multiplier applied to all
    /// colour channels. This value cannot be lower than 1.0.
    /// 
    /// Setting this value means that it is now fixed and the AE algorithm may
    /// not change it. Setting it back to zero returns it to the control of the
    /// AE algorithm.
    /// 
    /// \sa ExposureTime AeEnable
    /// 
    /// \todo Document the interactions between AeEnable and setting a fixed
    /// value for this control. Consider interactions with other AE features,
    /// such as aperture and aperture/shutter priority mode, and decide if
    /// control of which features should be automatically adjusted shouldn't
    /// better be handled through a separate AE mode control.
    AnalogueGain = 8,
    /// Specify a fixed brightness parameter. Positive values (up to 1.0)
    /// produce brighter images; negative values (up to -1.0) produce darker
    /// images and 0.0 leaves pixels unchanged.
    Brightness = 9,
    /// Specify a fixed contrast parameter. Normal contrast is given by the
    /// value 1.0; larger values produce images with more contrast.
    Contrast = 10,
    /// Report an estimate of the current illuminance level in lux. The Lux
    /// control can only be returned in metadata.
    Lux = 11,
    /// Enable or disable the AWB.
    /// 
    /// \sa ColourGains
    AwbEnable = 12,
    /// Specify the range of illuminants to use for the AWB algorithm. The modes
    /// supported are platform specific, and not all modes may be supported.
    AwbMode = 13,
    /// Report the lock status of a running AWB algorithm.
    /// 
    /// If the AWB algorithm is locked the value shall be set to true, if it's
    /// converging it shall be set to false. If the AWB algorithm is not
    /// running the control shall not be present in the metadata control list.
    /// 
    /// \sa AwbEnable
    AwbLocked = 14,
    /// Pair of gain values for the Red and Blue colour channels, in that
    /// order. ColourGains can only be applied in a Request when the AWB is
    /// disabled.
    /// 
    /// \sa AwbEnable
    ColourGains = 15,
    /// Report the current estimate of the colour temperature, in kelvin, for this frame. The ColourTemperature control can only be returned in metadata.
    ColourTemperature = 16,
    /// Specify a fixed saturation parameter. Normal saturation is given by
    /// the value 1.0; larger values produce more saturated colours; 0.0
    /// produces a greyscale image.
    Saturation = 17,
    /// Reports the sensor black levels used for processing a frame, in the
    /// order R, Gr, Gb, B. These values are returned as numbers out of a 16-bit
    /// pixel range (as if pixels ranged from 0 to 65535). The SensorBlackLevels
    /// control can only be returned in metadata.
    SensorBlackLevels = 18,
    /// A value of 0.0 means no sharpening. The minimum value means
    /// minimal sharpening, and shall be 0.0 unless the camera can't
    /// disable sharpening completely. The default value shall give a
    /// "reasonable" level of sharpening, suitable for most use cases.
    /// The maximum value may apply extremely high levels of sharpening,
    /// higher than anyone could reasonably want. Negative values are
    /// not allowed. Note also that sharpening is not applied to raw
    /// streams.
    Sharpness = 19,
    /// Reports a Figure of Merit (FoM) to indicate how in-focus the frame is.
    /// A larger FocusFoM value indicates a more in-focus frame. This control
    /// depends on the IPA to gather ISP statistics from the defined focus
    /// region, and combine them in a suitable way to generate a FocusFoM value.
    /// In this respect, it is not necessarily aimed at providing a way to
    /// implement a focus algorithm by the application, rather an indication of
    /// how in-focus a frame is.
    FocusFoM = 20,
    /// The 3x3 matrix that converts camera RGB to sRGB within the
    /// imaging pipeline. This should describe the matrix that is used
    /// after pixels have been white-balanced, but before any gamma
    /// transformation. The 3x3 matrix is stored in conventional reading
    /// order in an array of 9 floating point values.
    ColourCorrectionMatrix = 21,
    /// Sets the image portion that will be scaled to form the whole of
    /// the final output image. The (x,y) location of this rectangle is
    /// relative to the PixelArrayActiveAreas that is being used. The units
    /// remain native sensor pixels, even if the sensor is being used in
    /// a binning or skipping mode.
    /// 
    /// This control is only present when the pipeline supports scaling. Its
    /// maximum valid value is given by the properties::ScalerCropMaximum
    /// property, and the two can be used to implement digital zoom.
    ScalerCrop = 22,
    /// Digital gain value applied during the processing steps applied
    /// to the image as captured from the sensor.
    /// 
    /// The global digital gain factor is applied to all the colour channels
    /// of the RAW image. Different pipeline models are free to
    /// specify how the global gain factor applies to each separate
    /// channel.
    /// 
    /// If an imaging pipeline applies digital gain in distinct
    /// processing steps, this value indicates their total sum.
    /// Pipelines are free to decide how to adjust each processing
    /// step to respect the received gain factor and shall report
    /// their total value in the request metadata.
    DigitalGain = 23,
    /// The instantaneous frame duration from start of frame exposure to start
    /// of next exposure, expressed in microseconds. This control is meant to
    /// be returned in metadata.
    FrameDuration = 24,
    /// The minimum and maximum (in that order) frame duration,
    /// expressed in microseconds.
    /// 
    /// When provided by applications, the control specifies the sensor frame
    /// duration interval the pipeline has to use. This limits the largest
    /// exposure time the sensor can use. For example, if a maximum frame
    /// duration of 33ms is requested (corresponding to 30 frames per second),
    /// the sensor will not be able to raise the exposure time above 33ms.
    /// A fixed frame duration is achieved by setting the minimum and maximum
    /// values to be the same. Setting both values to 0 reverts to using the
    /// IPA provided defaults.
    /// 
    /// The maximum frame duration provides the absolute limit to the shutter
    /// speed computed by the AE algorithm and it overrides any exposure mode
    /// setting specified with controls::AeExposureMode. Similarly, when a
    /// manual exposure time is set through controls::ExposureTime, it also
    /// gets clipped to the limits set by this control. When reported in
    /// metadata, the control expresses the minimum and maximum frame
    /// durations used after being clipped to the sensor provided frame
    /// duration limits.
    /// 
    /// \sa AeExposureMode
    /// \sa ExposureTime
    /// 
    /// \todo Define how to calculate the capture frame rate by
    /// defining controls to report additional delays introduced by
    /// the capture pipeline or post-processing stages (ie JPEG
    /// conversion, frame scaling).
    /// 
    /// \todo Provide an explicit definition of default control values, for
    /// this and all other controls.
    FrameDurationLimits = 25,
    /// Temperature measure from the camera sensor in Celsius. This is typically
    /// obtained by a thermal sensor present on-die or in the camera module. The
    /// range of reported temperatures is device dependent.
    /// 
    /// The SensorTemperature control will only be returned in metadata if a
    /// themal sensor is present.
    SensorTemperature = 26,
    /// The time when the first row of the image sensor active array is exposed.
    /// 
    /// The timestamp, expressed in nanoseconds, represents a monotonically
    /// increasing counter since the system boot time, as defined by the
    /// Linux-specific CLOCK_BOOTTIME clock id.
    /// 
    /// The SensorTimestamp control can only be returned in metadata.
    /// 
    /// \todo Define how the sensor timestamp has to be used in the reprocessing
    /// use case.
    SensorTimestamp = 27,
    /// Control to set the mode of the AF (autofocus) algorithm.
    /// 
    /// An implementation may choose not to implement all the modes.
    AfMode = 28,
    /// Control to set the range of focus distances that is scanned. An
    /// implementation may choose not to implement all the options here.
    AfRange = 29,
    /// Control that determines whether the AF algorithm is to move the lens
    /// as quickly as possible or more steadily. For example, during video
    /// recording it may be desirable not to move the lens too abruptly, but
    /// when in a preview mode (waiting for a still capture) it may be
    /// helpful to move the lens as quickly as is reasonably possible.
    AfSpeed = 30,
    /// Instruct the AF algorithm how it should decide which parts of the image
    /// should be used to measure focus.
    AfMetering = 31,
    /// Sets the focus windows used by the AF algorithm when AfMetering is set
    /// to AfMeteringWindows. The units used are pixels within the rectangle
    /// returned by the ScalerCropMaximum property.
    /// 
    /// In order to be activated, a rectangle must be programmed with non-zero
    /// width and height. Internally, these rectangles are intersected with the
    /// ScalerCropMaximum rectangle. If the window becomes empty after this
    /// operation, then the window is ignored. If all the windows end up being
    /// ignored, then the behaviour is platform dependent.
    /// 
    /// On platforms that support the ScalerCrop control (for implementing
    /// digital zoom, for example), no automatic recalculation or adjustment of
    /// AF windows is performed internally if the ScalerCrop is changed. If any
    /// window lies outside the output image after the scaler crop has been
    /// applied, it is up to the application to recalculate them.
    /// 
    /// The details of how the windows are used are platform dependent. We note
    /// that when there is more than one AF window, a typical implementation
    /// might find the optimal focus position for each one and finally select
    /// the window where the focal distance for the objects shown in that part
    /// of the image are closest to the camera.
    AfWindows = 32,
    /// This control starts an autofocus scan when AfMode is set to AfModeAuto,
    /// and can also be used to terminate a scan early.
    /// 
    /// It is ignored if AfMode is set to AfModeManual or AfModeContinuous.
    AfTrigger = 33,
    /// This control has no effect except when in continuous autofocus mode
    /// (AfModeContinuous). It can be used to pause any lens movements while
    /// (for example) images are captured. The algorithm remains inactive
    /// until it is instructed to resume.
    AfPause = 34,
    /// Acts as a control to instruct the lens to move to a particular position
    /// and also reports back the position of the lens for each frame.
    /// 
    /// The LensPosition control is ignored unless the AfMode is set to
    /// AfModeManual, though the value is reported back unconditionally in all
    /// modes.
    /// 
    /// The units are a reciprocal distance scale like dioptres but normalised
    /// for the hyperfocal distance. That is, for a lens with hyperfocal
    /// distance H, and setting it to a focal distance D, the lens position LP,
    /// which is generally a non-integer, is given by
    /// 
    /// \f$LP = \frac{H}{D}\f$
    /// 
    /// For example:
    /// 
    /// 0 moves the lens to infinity.
    /// 0.5 moves the lens to twice the hyperfocal distance.
    /// 1 moves the lens to the hyperfocal position.
    /// And larger values will focus the lens ever closer.
    /// 
    /// \todo Define a property to report the Hyperforcal distance of calibrated
    /// lenses.
    /// 
    /// \todo Define a property to report the maximum and minimum positions of
    /// this lens. The minimum value will often be zero (meaning infinity).
    LensPosition = 35,
    /// Reports the current state of the AF algorithm in conjunction with the
    /// reported AfMode value and (in continuous AF mode) the AfPauseState
    /// value. The possible state changes are described below, though we note
    /// the following state transitions that occur when the AfMode is changed.
    /// 
    /// If the AfMode is set to AfModeManual, then the AfState will always
    /// report AfStateIdle (even if the lens is subsequently moved). Changing to
    /// the AfModeManual state does not initiate any lens movement.
    /// 
    /// If the AfMode is set to AfModeAuto then the AfState will report
    /// AfStateIdle. However, if AfModeAuto and AfTriggerStart are sent together
    /// then AfState will omit AfStateIdle and move straight to AfStateScanning
    /// (and start a scan).
    /// 
    /// If the AfMode is set to AfModeContinuous then the AfState will initially
    /// report AfStateScanning.
    AfState = 36,
    /// Only applicable in continuous (AfModeContinuous) mode, this reports
    /// whether the algorithm is currently running, paused or pausing (that is,
    /// will pause as soon as any in-progress scan completes).
    /// 
    /// Any change to AfMode will cause AfPauseStateRunning to be reported.
    AfPauseState = 37,
    /// Control for AE metering trigger. Currently identical to
    /// ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER.
    /// 
    /// Whether the camera device will trigger a precapture metering sequence
    /// when it processes this request.
    AePrecaptureTrigger = 38,
    /// Control to select the noise reduction algorithm mode. Currently
    /// identical to ANDROID_NOISE_REDUCTION_MODE.
    /// 
    ///  Mode of operation for the noise reduction algorithm.
    NoiseReductionMode = 39,
    /// Control to select the color correction aberration mode. Currently
    /// identical to ANDROID_COLOR_CORRECTION_ABERRATION_MODE.
    /// 
    ///  Mode of operation for the chromatic aberration correction algorithm.
    ColorCorrectionAberrationMode = 40,
    /// Control to report the current AE algorithm state. Currently identical to
    /// ANDROID_CONTROL_AE_STATE.
    /// 
    ///  Current state of the AE algorithm.
    AeState = 41,
    /// Control to report the current AWB algorithm state. Currently identical
    /// to ANDROID_CONTROL_AWB_STATE.
    /// 
    ///  Current state of the AWB algorithm.
    AwbState = 42,
    /// Control to report the time between the start of exposure of the first
    /// row and the start of exposure of the last row. Currently identical to
    /// ANDROID_SENSOR_ROLLING_SHUTTER_SKEW
    SensorRollingShutterSkew = 43,
    /// Control to report if the lens shading map is available. Currently
    /// identical to ANDROID_STATISTICS_LENS_SHADING_MAP_MODE.
    LensShadingMapMode = 44,
    /// Control to report the detected scene light frequency. Currently
    /// identical to ANDROID_STATISTICS_SCENE_FLICKER.
    SceneFlicker = 45,
    /// Specifies the number of pipeline stages the frame went through from when
    /// it was exposed to when the final completed result was available to the
    /// framework. Always less than or equal to PipelineMaxDepth. Currently
    /// identical to ANDROID_REQUEST_PIPELINE_DEPTH.
    /// 
    /// The typical value for this control is 3 as a frame is first exposed,
    /// captured and then processed in a single pass through the ISP. Any
    /// additional processing step performed after the ISP pass (in example face
    /// detection, additional format conversions etc) count as an additional
    /// pipeline stage.
    PipelineDepth = 46,
    /// The maximum number of frames that can occur after a request (different
    /// than the previous) has been submitted, and before the result's state
    /// becomes synchronized. A value of -1 indicates unknown latency, and 0
    /// indicates per-frame control. Currently identical to
    /// ANDROID_SYNC_MAX_LATENCY.
    MaxLatency = 47,
    /// Control to select the test pattern mode. Currently identical to
    /// ANDROID_SENSOR_TEST_PATTERN_MODE.
    TestPatternMode = 48,
}

/// Enable or disable the AE.
/// 
/// \sa ExposureTime AnalogueGain
#[derive(Debug, Clone)]
pub struct AeEnable(pub bool);

impl TryFrom<bool> for AeEnable {
    type Error = ControlValueError;

    fn try_from(value: bool) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<bool> for AeEnable {
    fn into(self) -> bool {
        self.0
    }
}

impl Control for AeEnable {
    const ID: u32 = ControlId::AeEnable as _;
    type T = bool;
}

/// Report the lock status of a running AE algorithm.
/// 
/// If the AE algorithm is locked the value shall be set to true, if it's
/// converging it shall be set to false. If the AE algorithm is not
/// running the control shall not be present in the metadata control list.
/// 
/// \sa AeEnable
#[derive(Debug, Clone)]
pub struct AeLocked(pub bool);

impl TryFrom<bool> for AeLocked {
    type Error = ControlValueError;

    fn try_from(value: bool) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<bool> for AeLocked {
    fn into(self) -> bool {
        self.0
    }
}

impl Control for AeLocked {
    const ID: u32 = ControlId::AeLocked as _;
    type T = bool;
}

/// Specify a metering mode for the AE algorithm to use. The metering
/// modes determine which parts of the image are used to determine the
/// scene brightness. Metering modes may be platform specific and not
/// all metering modes may be supported.
#[derive(Debug, Clone)]
pub enum AeMeteringMode {
    /// Centre-weighted metering mode.
    MeteringCentreWeighted = 0,
    /// Spot metering mode.
    MeteringSpot = 1,
    /// Matrix metering mode.
    MeteringMatrix = 2,
    /// Custom metering mode.
    MeteringCustom = 3,
}

impl TryFrom<i32> for AeMeteringMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::MeteringCentreWeighted),
1 => Ok(Self::MeteringSpot),
2 => Ok(Self::MeteringMatrix),
3 => Ok(Self::MeteringCustom),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AeMeteringMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AeMeteringMode {
    const ID: u32 = ControlId::AeMeteringMode as _;
    type T = i32;
}

/// Specify a constraint mode for the AE algorithm to use. These determine
/// how the measured scene brightness is adjusted to reach the desired
/// target exposure. Constraint modes may be platform specific, and not
/// all constraint modes may be supported.
#[derive(Debug, Clone)]
pub enum AeConstraintMode {
    /// Default constraint mode. This mode aims to balance the exposure of different parts of the image so as to reach a reasonable average level. However, highlights in the image may appear over-exposed and lowlights may appear under-exposed.
    ConstraintNormal = 0,
    /// Highlight constraint mode. This mode adjusts the exposure levels in order to try and avoid over-exposing the brightest parts (highlights) of an image. Other non-highlight parts of the image may appear under-exposed.
    ConstraintHighlight = 1,
    /// Shadows constraint mode. This mode adjusts the exposure levels in order to try and avoid under-exposing the dark parts (shadows) of an image. Other normally exposed parts of the image may appear over-exposed.
    ConstraintShadows = 2,
    /// Custom constraint mode.
    ConstraintCustom = 3,
}

impl TryFrom<i32> for AeConstraintMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::ConstraintNormal),
1 => Ok(Self::ConstraintHighlight),
2 => Ok(Self::ConstraintShadows),
3 => Ok(Self::ConstraintCustom),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AeConstraintMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AeConstraintMode {
    const ID: u32 = ControlId::AeConstraintMode as _;
    type T = i32;
}

/// Specify an exposure mode for the AE algorithm to use. These specify
/// how the desired total exposure is divided between the shutter time
/// and the sensor's analogue gain. The exposure modes are platform
/// specific, and not all exposure modes may be supported.
#[derive(Debug, Clone)]
pub enum AeExposureMode {
    /// Default exposure mode.
    ExposureNormal = 0,
    /// Exposure mode allowing only short exposure times.
    ExposureShort = 1,
    /// Exposure mode allowing long exposure times.
    ExposureLong = 2,
    /// Custom exposure mode.
    ExposureCustom = 3,
}

impl TryFrom<i32> for AeExposureMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::ExposureNormal),
1 => Ok(Self::ExposureShort),
2 => Ok(Self::ExposureLong),
3 => Ok(Self::ExposureCustom),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AeExposureMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AeExposureMode {
    const ID: u32 = ControlId::AeExposureMode as _;
    type T = i32;
}

/// Specify an Exposure Value (EV) parameter. The EV parameter will only be
/// applied if the AE algorithm is currently enabled.
/// 
/// By convention EV adjusts the exposure as log2. For example
/// EV = [-2, -1, 0.5, 0, 0.5, 1, 2] results in an exposure adjustment
/// of [1/4x, 1/2x, 1/sqrt(2)x, 1x, sqrt(2)x, 2x, 4x].
/// 
/// \sa AeEnable
#[derive(Debug, Clone)]
pub struct ExposureValue(pub f32);

impl TryFrom<f32> for ExposureValue {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for ExposureValue {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for ExposureValue {
    const ID: u32 = ControlId::ExposureValue as _;
    type T = f32;
}

/// Exposure time (shutter speed) for the frame applied in the sensor
/// device. This value is specified in micro-seconds.
/// 
/// Setting this value means that it is now fixed and the AE algorithm may
/// not change it. Setting it back to zero returns it to the control of the
/// AE algorithm.
/// 
/// \sa AnalogueGain AeEnable
/// 
/// \todo Document the interactions between AeEnable and setting a fixed
/// value for this control. Consider interactions with other AE features,
/// such as aperture and aperture/shutter priority mode, and decide if
/// control of which features should be automatically adjusted shouldn't
/// better be handled through a separate AE mode control.
#[derive(Debug, Clone)]
pub struct ExposureTime(pub i32);

impl TryFrom<i32> for ExposureTime {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i32> for ExposureTime {
    fn into(self) -> i32 {
        self.0
    }
}

impl Control for ExposureTime {
    const ID: u32 = ControlId::ExposureTime as _;
    type T = i32;
}

/// Analogue gain value applied in the sensor device.
/// The value of the control specifies the gain multiplier applied to all
/// colour channels. This value cannot be lower than 1.0.
/// 
/// Setting this value means that it is now fixed and the AE algorithm may
/// not change it. Setting it back to zero returns it to the control of the
/// AE algorithm.
/// 
/// \sa ExposureTime AeEnable
/// 
/// \todo Document the interactions between AeEnable and setting a fixed
/// value for this control. Consider interactions with other AE features,
/// such as aperture and aperture/shutter priority mode, and decide if
/// control of which features should be automatically adjusted shouldn't
/// better be handled through a separate AE mode control.
#[derive(Debug, Clone)]
pub struct AnalogueGain(pub f32);

impl TryFrom<f32> for AnalogueGain {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for AnalogueGain {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for AnalogueGain {
    const ID: u32 = ControlId::AnalogueGain as _;
    type T = f32;
}

/// Specify a fixed brightness parameter. Positive values (up to 1.0)
/// produce brighter images; negative values (up to -1.0) produce darker
/// images and 0.0 leaves pixels unchanged.
#[derive(Debug, Clone)]
pub struct Brightness(pub f32);

impl TryFrom<f32> for Brightness {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for Brightness {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for Brightness {
    const ID: u32 = ControlId::Brightness as _;
    type T = f32;
}

/// Specify a fixed contrast parameter. Normal contrast is given by the
/// value 1.0; larger values produce images with more contrast.
#[derive(Debug, Clone)]
pub struct Contrast(pub f32);

impl TryFrom<f32> for Contrast {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for Contrast {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for Contrast {
    const ID: u32 = ControlId::Contrast as _;
    type T = f32;
}

/// Report an estimate of the current illuminance level in lux. The Lux
/// control can only be returned in metadata.
#[derive(Debug, Clone)]
pub struct Lux(pub f32);

impl TryFrom<f32> for Lux {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for Lux {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for Lux {
    const ID: u32 = ControlId::Lux as _;
    type T = f32;
}

/// Enable or disable the AWB.
/// 
/// \sa ColourGains
#[derive(Debug, Clone)]
pub struct AwbEnable(pub bool);

impl TryFrom<bool> for AwbEnable {
    type Error = ControlValueError;

    fn try_from(value: bool) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<bool> for AwbEnable {
    fn into(self) -> bool {
        self.0
    }
}

impl Control for AwbEnable {
    const ID: u32 = ControlId::AwbEnable as _;
    type T = bool;
}

/// Specify the range of illuminants to use for the AWB algorithm. The modes
/// supported are platform specific, and not all modes may be supported.
#[derive(Debug, Clone)]
pub enum AwbMode {
    /// Search over the whole colour temperature range.
    AwbAuto = 0,
    /// Incandescent AWB lamp mode.
    AwbIncandescent = 1,
    /// Tungsten AWB lamp mode.
    AwbTungsten = 2,
    /// Fluorescent AWB lamp mode.
    AwbFluorescent = 3,
    /// Indoor AWB lighting mode.
    AwbIndoor = 4,
    /// Daylight AWB lighting mode.
    AwbDaylight = 5,
    /// Cloudy AWB lighting mode.
    AwbCloudy = 6,
    /// Custom AWB mode.
    AwbCustom = 7,
}

impl TryFrom<i32> for AwbMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::AwbAuto),
1 => Ok(Self::AwbIncandescent),
2 => Ok(Self::AwbTungsten),
3 => Ok(Self::AwbFluorescent),
4 => Ok(Self::AwbIndoor),
5 => Ok(Self::AwbDaylight),
6 => Ok(Self::AwbCloudy),
7 => Ok(Self::AwbCustom),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AwbMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AwbMode {
    const ID: u32 = ControlId::AwbMode as _;
    type T = i32;
}

/// Report the lock status of a running AWB algorithm.
/// 
/// If the AWB algorithm is locked the value shall be set to true, if it's
/// converging it shall be set to false. If the AWB algorithm is not
/// running the control shall not be present in the metadata control list.
/// 
/// \sa AwbEnable
#[derive(Debug, Clone)]
pub struct AwbLocked(pub bool);

impl TryFrom<bool> for AwbLocked {
    type Error = ControlValueError;

    fn try_from(value: bool) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<bool> for AwbLocked {
    fn into(self) -> bool {
        self.0
    }
}

impl Control for AwbLocked {
    const ID: u32 = ControlId::AwbLocked as _;
    type T = bool;
}

/// Pair of gain values for the Red and Blue colour channels, in that
/// order. ColourGains can only be applied in a Request when the AWB is
/// disabled.
/// 
/// \sa AwbEnable
#[derive(Debug, Clone)]
pub struct ColourGains(pub f32);

impl TryFrom<f32> for ColourGains {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for ColourGains {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for ColourGains {
    const ID: u32 = ControlId::ColourGains as _;
    type T = f32;
}

/// Report the current estimate of the colour temperature, in kelvin, for this frame. The ColourTemperature control can only be returned in metadata.
#[derive(Debug, Clone)]
pub struct ColourTemperature(pub i32);

impl TryFrom<i32> for ColourTemperature {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i32> for ColourTemperature {
    fn into(self) -> i32 {
        self.0
    }
}

impl Control for ColourTemperature {
    const ID: u32 = ControlId::ColourTemperature as _;
    type T = i32;
}

/// Specify a fixed saturation parameter. Normal saturation is given by
/// the value 1.0; larger values produce more saturated colours; 0.0
/// produces a greyscale image.
#[derive(Debug, Clone)]
pub struct Saturation(pub f32);

impl TryFrom<f32> for Saturation {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for Saturation {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for Saturation {
    const ID: u32 = ControlId::Saturation as _;
    type T = f32;
}

/// Reports the sensor black levels used for processing a frame, in the
/// order R, Gr, Gb, B. These values are returned as numbers out of a 16-bit
/// pixel range (as if pixels ranged from 0 to 65535). The SensorBlackLevels
/// control can only be returned in metadata.
#[derive(Debug, Clone)]
pub struct SensorBlackLevels(pub i32);

impl TryFrom<i32> for SensorBlackLevels {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i32> for SensorBlackLevels {
    fn into(self) -> i32 {
        self.0
    }
}

impl Control for SensorBlackLevels {
    const ID: u32 = ControlId::SensorBlackLevels as _;
    type T = i32;
}

/// A value of 0.0 means no sharpening. The minimum value means
/// minimal sharpening, and shall be 0.0 unless the camera can't
/// disable sharpening completely. The default value shall give a
/// "reasonable" level of sharpening, suitable for most use cases.
/// The maximum value may apply extremely high levels of sharpening,
/// higher than anyone could reasonably want. Negative values are
/// not allowed. Note also that sharpening is not applied to raw
/// streams.
#[derive(Debug, Clone)]
pub struct Sharpness(pub f32);

impl TryFrom<f32> for Sharpness {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for Sharpness {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for Sharpness {
    const ID: u32 = ControlId::Sharpness as _;
    type T = f32;
}

/// Reports a Figure of Merit (FoM) to indicate how in-focus the frame is.
/// A larger FocusFoM value indicates a more in-focus frame. This control
/// depends on the IPA to gather ISP statistics from the defined focus
/// region, and combine them in a suitable way to generate a FocusFoM value.
/// In this respect, it is not necessarily aimed at providing a way to
/// implement a focus algorithm by the application, rather an indication of
/// how in-focus a frame is.
#[derive(Debug, Clone)]
pub struct FocusFoM(pub i32);

impl TryFrom<i32> for FocusFoM {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i32> for FocusFoM {
    fn into(self) -> i32 {
        self.0
    }
}

impl Control for FocusFoM {
    const ID: u32 = ControlId::FocusFoM as _;
    type T = i32;
}

/// The 3x3 matrix that converts camera RGB to sRGB within the
/// imaging pipeline. This should describe the matrix that is used
/// after pixels have been white-balanced, but before any gamma
/// transformation. The 3x3 matrix is stored in conventional reading
/// order in an array of 9 floating point values.
#[derive(Debug, Clone)]
pub struct ColourCorrectionMatrix(pub f32);

impl TryFrom<f32> for ColourCorrectionMatrix {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for ColourCorrectionMatrix {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for ColourCorrectionMatrix {
    const ID: u32 = ControlId::ColourCorrectionMatrix as _;
    type T = f32;
}

/// Sets the image portion that will be scaled to form the whole of
/// the final output image. The (x,y) location of this rectangle is
/// relative to the PixelArrayActiveAreas that is being used. The units
/// remain native sensor pixels, even if the sensor is being used in
/// a binning or skipping mode.
/// 
/// This control is only present when the pipeline supports scaling. Its
/// maximum valid value is given by the properties::ScalerCropMaximum
/// property, and the two can be used to implement digital zoom.
#[derive(Debug, Clone)]
pub struct ScalerCrop(pub ());

impl TryFrom<()> for ScalerCrop {
    type Error = ControlValueError;

    fn try_from(value: ()) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<()> for ScalerCrop {
    fn into(self) -> () {
        self.0
    }
}

impl Control for ScalerCrop {
    const ID: u32 = ControlId::ScalerCrop as _;
    type T = ();
}

/// Digital gain value applied during the processing steps applied
/// to the image as captured from the sensor.
/// 
/// The global digital gain factor is applied to all the colour channels
/// of the RAW image. Different pipeline models are free to
/// specify how the global gain factor applies to each separate
/// channel.
/// 
/// If an imaging pipeline applies digital gain in distinct
/// processing steps, this value indicates their total sum.
/// Pipelines are free to decide how to adjust each processing
/// step to respect the received gain factor and shall report
/// their total value in the request metadata.
#[derive(Debug, Clone)]
pub struct DigitalGain(pub f32);

impl TryFrom<f32> for DigitalGain {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for DigitalGain {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for DigitalGain {
    const ID: u32 = ControlId::DigitalGain as _;
    type T = f32;
}

/// The instantaneous frame duration from start of frame exposure to start
/// of next exposure, expressed in microseconds. This control is meant to
/// be returned in metadata.
#[derive(Debug, Clone)]
pub struct FrameDuration(pub i64);

impl TryFrom<i64> for FrameDuration {
    type Error = ControlValueError;

    fn try_from(value: i64) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i64> for FrameDuration {
    fn into(self) -> i64 {
        self.0
    }
}

impl Control for FrameDuration {
    const ID: u32 = ControlId::FrameDuration as _;
    type T = i64;
}

/// The minimum and maximum (in that order) frame duration,
/// expressed in microseconds.
/// 
/// When provided by applications, the control specifies the sensor frame
/// duration interval the pipeline has to use. This limits the largest
/// exposure time the sensor can use. For example, if a maximum frame
/// duration of 33ms is requested (corresponding to 30 frames per second),
/// the sensor will not be able to raise the exposure time above 33ms.
/// A fixed frame duration is achieved by setting the minimum and maximum
/// values to be the same. Setting both values to 0 reverts to using the
/// IPA provided defaults.
/// 
/// The maximum frame duration provides the absolute limit to the shutter
/// speed computed by the AE algorithm and it overrides any exposure mode
/// setting specified with controls::AeExposureMode. Similarly, when a
/// manual exposure time is set through controls::ExposureTime, it also
/// gets clipped to the limits set by this control. When reported in
/// metadata, the control expresses the minimum and maximum frame
/// durations used after being clipped to the sensor provided frame
/// duration limits.
/// 
/// \sa AeExposureMode
/// \sa ExposureTime
/// 
/// \todo Define how to calculate the capture frame rate by
/// defining controls to report additional delays introduced by
/// the capture pipeline or post-processing stages (ie JPEG
/// conversion, frame scaling).
/// 
/// \todo Provide an explicit definition of default control values, for
/// this and all other controls.
#[derive(Debug, Clone)]
pub struct FrameDurationLimits(pub i64);

impl TryFrom<i64> for FrameDurationLimits {
    type Error = ControlValueError;

    fn try_from(value: i64) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i64> for FrameDurationLimits {
    fn into(self) -> i64 {
        self.0
    }
}

impl Control for FrameDurationLimits {
    const ID: u32 = ControlId::FrameDurationLimits as _;
    type T = i64;
}

/// Temperature measure from the camera sensor in Celsius. This is typically
/// obtained by a thermal sensor present on-die or in the camera module. The
/// range of reported temperatures is device dependent.
/// 
/// The SensorTemperature control will only be returned in metadata if a
/// themal sensor is present.
#[derive(Debug, Clone)]
pub struct SensorTemperature(pub f32);

impl TryFrom<f32> for SensorTemperature {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for SensorTemperature {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for SensorTemperature {
    const ID: u32 = ControlId::SensorTemperature as _;
    type T = f32;
}

/// The time when the first row of the image sensor active array is exposed.
/// 
/// The timestamp, expressed in nanoseconds, represents a monotonically
/// increasing counter since the system boot time, as defined by the
/// Linux-specific CLOCK_BOOTTIME clock id.
/// 
/// The SensorTimestamp control can only be returned in metadata.
/// 
/// \todo Define how the sensor timestamp has to be used in the reprocessing
/// use case.
#[derive(Debug, Clone)]
pub struct SensorTimestamp(pub i64);

impl TryFrom<i64> for SensorTimestamp {
    type Error = ControlValueError;

    fn try_from(value: i64) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i64> for SensorTimestamp {
    fn into(self) -> i64 {
        self.0
    }
}

impl Control for SensorTimestamp {
    const ID: u32 = ControlId::SensorTimestamp as _;
    type T = i64;
}

/// Control to set the mode of the AF (autofocus) algorithm.
/// 
/// An implementation may choose not to implement all the modes.
#[derive(Debug, Clone)]
pub enum AfMode {
    /// The AF algorithm is in manual mode. In this mode it will never
    /// perform any action nor move the lens of its own accord, but an
    /// application can specify the desired lens position using the
    /// LensPosition control.
    /// 
    /// In this mode the AfState will always report AfStateIdle.
    Manual = 0,
    /// The AF algorithm is in auto mode. This means that the algorithm
    /// will never move the lens or change state unless the AfTrigger
    /// control is used. The AfTrigger control can be used to initiate a
    /// focus scan, the results of which will be reported by AfState.
    /// 
    /// If the autofocus algorithm is moved from AfModeAuto to another
    /// mode while a scan is in progress, the scan is cancelled
    /// immediately, without waiting for the scan to finish.
    /// 
    /// When first entering this mode the AfState will report
    /// AfStateIdle. When a trigger control is sent, AfState will
    /// report AfStateScanning for a period before spontaneously
    /// changing to AfStateFocused or AfStateFailed, depending on
    /// the outcome of the scan. It will remain in this state until
    /// another scan is initiated by the AfTrigger control. If a scan is
    /// cancelled (without changing to another mode), AfState will return
    /// to AfStateIdle.
    Auto = 1,
    /// The AF algorithm is in continuous mode. This means that the lens can
    /// re-start a scan spontaneously at any moment, without any user
    /// intervention. The AfState still reports whether the algorithm is
    /// currently scanning or not, though the application has no ability to
    /// initiate or cancel scans, nor to move the lens for itself.
    /// 
    /// However, applications can pause the AF algorithm from continuously
    /// scanning by using the AfPause control. This allows video or still
    /// images to be captured whilst guaranteeing that the focus is fixed.
    /// 
    /// When set to AfModeContinuous, the system will immediately initiate a
    /// scan so AfState will report AfStateScanning, and will settle on one
    /// of AfStateFocused or AfStateFailed, depending on the scan result.
    Continuous = 2,
}

impl TryFrom<i32> for AfMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Manual),
1 => Ok(Self::Auto),
2 => Ok(Self::Continuous),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfMode {
    const ID: u32 = ControlId::AfMode as _;
    type T = i32;
}

/// Control to set the range of focus distances that is scanned. An
/// implementation may choose not to implement all the options here.
#[derive(Debug, Clone)]
pub enum AfRange {
    /// A wide range of focus distances is scanned, all the way from
    /// infinity down to close distances, though depending on the
    /// implementation, possibly not including the very closest macro
    /// positions.
    Normal = 0,
    /// Only close distances are scanned.
    Macro = 1,
    /// The full range of focus distances is scanned just as with
    /// AfRangeNormal but this time including the very closest macro
    /// positions.
    Full = 2,
}

impl TryFrom<i32> for AfRange {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Normal),
1 => Ok(Self::Macro),
2 => Ok(Self::Full),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfRange {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfRange {
    const ID: u32 = ControlId::AfRange as _;
    type T = i32;
}

/// Control that determines whether the AF algorithm is to move the lens
/// as quickly as possible or more steadily. For example, during video
/// recording it may be desirable not to move the lens too abruptly, but
/// when in a preview mode (waiting for a still capture) it may be
/// helpful to move the lens as quickly as is reasonably possible.
#[derive(Debug, Clone)]
pub enum AfSpeed {
    /// Move the lens at its usual speed.
    Normal = 0,
    /// Move the lens more quickly.
    Fast = 1,
}

impl TryFrom<i32> for AfSpeed {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Normal),
1 => Ok(Self::Fast),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfSpeed {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfSpeed {
    const ID: u32 = ControlId::AfSpeed as _;
    type T = i32;
}

/// Instruct the AF algorithm how it should decide which parts of the image
/// should be used to measure focus.
#[derive(Debug, Clone)]
pub enum AfMetering {
    /// The AF algorithm should decide for itself where it will measure focus.
    Auto = 0,
    /// The AF algorithm should use the rectangles defined by the AfWindows control to measure focus. If no windows are specified the behaviour is platform dependent.
    Windows = 1,
}

impl TryFrom<i32> for AfMetering {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Auto),
1 => Ok(Self::Windows),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfMetering {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfMetering {
    const ID: u32 = ControlId::AfMetering as _;
    type T = i32;
}

/// Sets the focus windows used by the AF algorithm when AfMetering is set
/// to AfMeteringWindows. The units used are pixels within the rectangle
/// returned by the ScalerCropMaximum property.
/// 
/// In order to be activated, a rectangle must be programmed with non-zero
/// width and height. Internally, these rectangles are intersected with the
/// ScalerCropMaximum rectangle. If the window becomes empty after this
/// operation, then the window is ignored. If all the windows end up being
/// ignored, then the behaviour is platform dependent.
/// 
/// On platforms that support the ScalerCrop control (for implementing
/// digital zoom, for example), no automatic recalculation or adjustment of
/// AF windows is performed internally if the ScalerCrop is changed. If any
/// window lies outside the output image after the scaler crop has been
/// applied, it is up to the application to recalculate them.
/// 
/// The details of how the windows are used are platform dependent. We note
/// that when there is more than one AF window, a typical implementation
/// might find the optimal focus position for each one and finally select
/// the window where the focal distance for the objects shown in that part
/// of the image are closest to the camera.
#[derive(Debug, Clone)]
pub struct AfWindows(pub ());

impl TryFrom<()> for AfWindows {
    type Error = ControlValueError;

    fn try_from(value: ()) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<()> for AfWindows {
    fn into(self) -> () {
        self.0
    }
}

impl Control for AfWindows {
    const ID: u32 = ControlId::AfWindows as _;
    type T = ();
}

/// This control starts an autofocus scan when AfMode is set to AfModeAuto,
/// and can also be used to terminate a scan early.
/// 
/// It is ignored if AfMode is set to AfModeManual or AfModeContinuous.
#[derive(Debug, Clone)]
pub enum AfTrigger {
    /// Start an AF scan. Ignored if a scan is in progress.
    Start = 0,
    /// Cancel an AF scan. This does not cause the lens to move anywhere else. Ignored if no scan is in progress.
    Cancel = 1,
}

impl TryFrom<i32> for AfTrigger {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Start),
1 => Ok(Self::Cancel),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfTrigger {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfTrigger {
    const ID: u32 = ControlId::AfTrigger as _;
    type T = i32;
}

/// This control has no effect except when in continuous autofocus mode
/// (AfModeContinuous). It can be used to pause any lens movements while
/// (for example) images are captured. The algorithm remains inactive
/// until it is instructed to resume.
#[derive(Debug, Clone)]
pub enum AfPause {
    /// Pause the continuous autofocus algorithm immediately, whether or not
    /// any kind of scan is underway. AfPauseState will subsequently report
    /// AfPauseStatePaused. AfState may report any of AfStateScanning,
    /// AfStateFocused or AfStateFailed, depending on the algorithm's state
    /// when it received this control.
    Immediate = 0,
    /// This is similar to AfPauseImmediate, and if the AfState is currently
    /// reporting AfStateFocused or AfStateFailed it will remain in that
    /// state and AfPauseState will report AfPauseStatePaused.
    /// 
    /// However, if the algorithm is scanning (AfStateScanning),
    /// AfPauseState will report AfPauseStatePausing until the scan is
    /// finished, at which point AfState will report one of AfStateFocused
    /// or AfStateFailed, and AfPauseState will change to
    /// AfPauseStatePaused.
    Deferred = 1,
    /// Resume continuous autofocus operation. The algorithm starts again
    /// from exactly where it left off, and AfPauseState will report
    /// AfPauseStateRunning.
    Resume = 2,
}

impl TryFrom<i32> for AfPause {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Immediate),
1 => Ok(Self::Deferred),
2 => Ok(Self::Resume),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfPause {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfPause {
    const ID: u32 = ControlId::AfPause as _;
    type T = i32;
}

/// Acts as a control to instruct the lens to move to a particular position
/// and also reports back the position of the lens for each frame.
/// 
/// The LensPosition control is ignored unless the AfMode is set to
/// AfModeManual, though the value is reported back unconditionally in all
/// modes.
/// 
/// The units are a reciprocal distance scale like dioptres but normalised
/// for the hyperfocal distance. That is, for a lens with hyperfocal
/// distance H, and setting it to a focal distance D, the lens position LP,
/// which is generally a non-integer, is given by
/// 
/// \f$LP = \frac{H}{D}\f$
/// 
/// For example:
/// 
/// 0 moves the lens to infinity.
/// 0.5 moves the lens to twice the hyperfocal distance.
/// 1 moves the lens to the hyperfocal position.
/// And larger values will focus the lens ever closer.
/// 
/// \todo Define a property to report the Hyperforcal distance of calibrated
/// lenses.
/// 
/// \todo Define a property to report the maximum and minimum positions of
/// this lens. The minimum value will often be zero (meaning infinity).
#[derive(Debug, Clone)]
pub struct LensPosition(pub f32);

impl TryFrom<f32> for LensPosition {
    type Error = ControlValueError;

    fn try_from(value: f32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<f32> for LensPosition {
    fn into(self) -> f32 {
        self.0
    }
}

impl Control for LensPosition {
    const ID: u32 = ControlId::LensPosition as _;
    type T = f32;
}

/// Reports the current state of the AF algorithm in conjunction with the
/// reported AfMode value and (in continuous AF mode) the AfPauseState
/// value. The possible state changes are described below, though we note
/// the following state transitions that occur when the AfMode is changed.
/// 
/// If the AfMode is set to AfModeManual, then the AfState will always
/// report AfStateIdle (even if the lens is subsequently moved). Changing to
/// the AfModeManual state does not initiate any lens movement.
/// 
/// If the AfMode is set to AfModeAuto then the AfState will report
/// AfStateIdle. However, if AfModeAuto and AfTriggerStart are sent together
/// then AfState will omit AfStateIdle and move straight to AfStateScanning
/// (and start a scan).
/// 
/// If the AfMode is set to AfModeContinuous then the AfState will initially
/// report AfStateScanning.
#[derive(Debug, Clone)]
pub enum AfState {
    /// The AF algorithm is in manual mode (AfModeManual) or in auto mode
    /// (AfModeAuto) and a scan has not yet been triggered, or an
    /// in-progress scan was cancelled.
    Idle = 0,
    /// The AF algorithm is in auto mode (AfModeAuto), and a scan has been
    /// started using the AfTrigger control. The scan can be cancelled by
    /// sending AfTriggerCancel at which point the algorithm will either
    /// move back to AfStateIdle or, if the scan actually completes before
    /// the cancel request is processed, to one of AfStateFocused or
    /// AfStateFailed.
    /// 
    /// Alternatively the AF algorithm could be in continuous mode
    /// (AfModeContinuous) at which point it may enter this state
    /// spontaneously whenever it determines that a rescan is needed.
    Scanning = 1,
    /// The AF algorithm is in auto (AfModeAuto) or continuous
    /// (AfModeContinuous) mode and a scan has completed with the result
    /// that the algorithm believes the image is now in focus.
    Focused = 2,
    /// The AF algorithm is in auto (AfModeAuto) or continuous
    /// (AfModeContinuous) mode and a scan has completed with the result
    /// that the algorithm did not find a good focus position.
    Failed = 3,
}

impl TryFrom<i32> for AfState {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Idle),
1 => Ok(Self::Scanning),
2 => Ok(Self::Focused),
3 => Ok(Self::Failed),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfState {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfState {
    const ID: u32 = ControlId::AfState as _;
    type T = i32;
}

/// Only applicable in continuous (AfModeContinuous) mode, this reports
/// whether the algorithm is currently running, paused or pausing (that is,
/// will pause as soon as any in-progress scan completes).
/// 
/// Any change to AfMode will cause AfPauseStateRunning to be reported.
#[derive(Debug, Clone)]
pub enum AfPauseState {
    /// Continuous AF is running and the algorithm may restart a scan
    /// spontaneously.
    Running = 0,
    /// Continuous AF has been sent an AfPauseDeferred control, and will
    /// pause as soon as any in-progress scan completes (and then report
    /// AfPauseStatePaused). No new scans will be start spontaneously until
    /// the AfPauseResume control is sent.
    Pausing = 1,
    /// Continuous AF is paused. No further state changes or lens movements
    /// will occur until the AfPauseResume control is sent.
    Paused = 2,
}

impl TryFrom<i32> for AfPauseState {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Running),
1 => Ok(Self::Pausing),
2 => Ok(Self::Paused),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AfPauseState {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AfPauseState {
    const ID: u32 = ControlId::AfPauseState as _;
    type T = i32;
}

/// Control for AE metering trigger. Currently identical to
/// ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER.
/// 
/// Whether the camera device will trigger a precapture metering sequence
/// when it processes this request.
#[derive(Debug, Clone)]
pub enum AePrecaptureTrigger {
    /// The trigger is idle.
    Idle = 0,
    /// The pre-capture AE metering is started by the camera.
    Start = 1,
    /// The camera will cancel any active or completed metering sequence.
    /// The AE algorithm is reset to its initial state.
    Cancel = 2,
}

impl TryFrom<i32> for AePrecaptureTrigger {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Idle),
1 => Ok(Self::Start),
2 => Ok(Self::Cancel),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AePrecaptureTrigger {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AePrecaptureTrigger {
    const ID: u32 = ControlId::AePrecaptureTrigger as _;
    type T = i32;
}

/// Control to select the noise reduction algorithm mode. Currently
/// identical to ANDROID_NOISE_REDUCTION_MODE.
/// 
///  Mode of operation for the noise reduction algorithm.
#[derive(Debug, Clone)]
pub enum NoiseReductionMode {
    /// No noise reduction is applied
    Off = 0,
    /// Noise reduction is applied without reducing the frame rate.
    Fast = 1,
    /// High quality noise reduction at the expense of frame rate.
    HighQuality = 2,
    /// Minimal noise reduction is applied without reducing the frame rate.
    Minimal = 3,
    /// Noise reduction is applied at different levels to different streams.
    ZSL = 4,
}

impl TryFrom<i32> for NoiseReductionMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Off),
1 => Ok(Self::Fast),
2 => Ok(Self::HighQuality),
3 => Ok(Self::Minimal),
4 => Ok(Self::ZSL),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for NoiseReductionMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for NoiseReductionMode {
    const ID: u32 = ControlId::NoiseReductionMode as _;
    type T = i32;
}

/// Control to select the color correction aberration mode. Currently
/// identical to ANDROID_COLOR_CORRECTION_ABERRATION_MODE.
/// 
///  Mode of operation for the chromatic aberration correction algorithm.
#[derive(Debug, Clone)]
pub enum ColorCorrectionAberrationMode {
    /// No aberration correction is applied.
    ColorCorrectionAberrationOff = 0,
    /// Aberration correction will not slow down the frame rate.
    ColorCorrectionAberrationFast = 1,
    /// High quality aberration correction which might reduce the frame
    /// rate.
    ColorCorrectionAberrationHighQuality = 2,
}

impl TryFrom<i32> for ColorCorrectionAberrationMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::ColorCorrectionAberrationOff),
1 => Ok(Self::ColorCorrectionAberrationFast),
2 => Ok(Self::ColorCorrectionAberrationHighQuality),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for ColorCorrectionAberrationMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for ColorCorrectionAberrationMode {
    const ID: u32 = ControlId::ColorCorrectionAberrationMode as _;
    type T = i32;
}

/// Control to report the current AE algorithm state. Currently identical to
/// ANDROID_CONTROL_AE_STATE.
/// 
///  Current state of the AE algorithm.
#[derive(Debug, Clone)]
pub enum AeState {
    /// The AE algorithm is inactive.
    Inactive = 0,
    /// The AE algorithm has not converged yet.
    Searching = 1,
    /// The AE algorithm has converged.
    Converged = 2,
    /// The AE algorithm is locked.
    Locked = 3,
    /// The AE algorithm would need a flash for good results
    FlashRequired = 4,
    /// The AE algorithm has started a pre-capture metering session.
    /// \sa AePrecaptureTrigger
    Precapture = 5,
}

impl TryFrom<i32> for AeState {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Inactive),
1 => Ok(Self::Searching),
2 => Ok(Self::Converged),
3 => Ok(Self::Locked),
4 => Ok(Self::FlashRequired),
5 => Ok(Self::Precapture),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AeState {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AeState {
    const ID: u32 = ControlId::AeState as _;
    type T = i32;
}

/// Control to report the current AWB algorithm state. Currently identical
/// to ANDROID_CONTROL_AWB_STATE.
/// 
///  Current state of the AWB algorithm.
#[derive(Debug, Clone)]
pub enum AwbState {
    /// The AWB algorithm is inactive.
    Inactive = 0,
    /// The AWB algorithm has not converged yet.
    Searching = 1,
    /// The AWB algorithm has converged.
    AwbConverged = 2,
    /// The AWB algorithm is locked.
    AwbLocked = 3,
}

impl TryFrom<i32> for AwbState {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Inactive),
1 => Ok(Self::Searching),
2 => Ok(Self::AwbConverged),
3 => Ok(Self::AwbLocked),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for AwbState {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for AwbState {
    const ID: u32 = ControlId::AwbState as _;
    type T = i32;
}

/// Control to report the time between the start of exposure of the first
/// row and the start of exposure of the last row. Currently identical to
/// ANDROID_SENSOR_ROLLING_SHUTTER_SKEW
#[derive(Debug, Clone)]
pub struct SensorRollingShutterSkew(pub i64);

impl TryFrom<i64> for SensorRollingShutterSkew {
    type Error = ControlValueError;

    fn try_from(value: i64) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i64> for SensorRollingShutterSkew {
    fn into(self) -> i64 {
        self.0
    }
}

impl Control for SensorRollingShutterSkew {
    const ID: u32 = ControlId::SensorRollingShutterSkew as _;
    type T = i64;
}

/// Control to report if the lens shading map is available. Currently
/// identical to ANDROID_STATISTICS_LENS_SHADING_MAP_MODE.
#[derive(Debug, Clone)]
pub enum LensShadingMapMode {
    /// No lens shading map mode is available.
    Off = 0,
    /// The lens shading map mode is available.
    On = 1,
}

impl TryFrom<i32> for LensShadingMapMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Off),
1 => Ok(Self::On),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for LensShadingMapMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for LensShadingMapMode {
    const ID: u32 = ControlId::LensShadingMapMode as _;
    type T = i32;
}

/// Control to report the detected scene light frequency. Currently
/// identical to ANDROID_STATISTICS_SCENE_FLICKER.
#[derive(Debug, Clone)]
pub enum SceneFlicker {
    /// No flickering detected.
    SceneFickerOff = 0,
    /// 50Hz flickering detected.
    SceneFicker50Hz = 1,
    /// 60Hz flickering detected.
    SceneFicker60Hz = 2,
}

impl TryFrom<i32> for SceneFlicker {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::SceneFickerOff),
1 => Ok(Self::SceneFicker50Hz),
2 => Ok(Self::SceneFicker60Hz),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for SceneFlicker {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for SceneFlicker {
    const ID: u32 = ControlId::SceneFlicker as _;
    type T = i32;
}

/// Specifies the number of pipeline stages the frame went through from when
/// it was exposed to when the final completed result was available to the
/// framework. Always less than or equal to PipelineMaxDepth. Currently
/// identical to ANDROID_REQUEST_PIPELINE_DEPTH.
/// 
/// The typical value for this control is 3 as a frame is first exposed,
/// captured and then processed in a single pass through the ISP. Any
/// additional processing step performed after the ISP pass (in example face
/// detection, additional format conversions etc) count as an additional
/// pipeline stage.
#[derive(Debug, Clone)]
pub struct PipelineDepth(pub i32);

impl TryFrom<i32> for PipelineDepth {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i32> for PipelineDepth {
    fn into(self) -> i32 {
        self.0
    }
}

impl Control for PipelineDepth {
    const ID: u32 = ControlId::PipelineDepth as _;
    type T = i32;
}

/// The maximum number of frames that can occur after a request (different
/// than the previous) has been submitted, and before the result's state
/// becomes synchronized. A value of -1 indicates unknown latency, and 0
/// indicates per-frame control. Currently identical to
/// ANDROID_SYNC_MAX_LATENCY.
#[derive(Debug, Clone)]
pub struct MaxLatency(pub i32);

impl TryFrom<i32> for MaxLatency {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        Ok(Self(value))
    }
}

impl Into<i32> for MaxLatency {
    fn into(self) -> i32 {
        self.0
    }
}

impl Control for MaxLatency {
    const ID: u32 = ControlId::MaxLatency as _;
    type T = i32;
}

/// Control to select the test pattern mode. Currently identical to
/// ANDROID_SENSOR_TEST_PATTERN_MODE.
#[derive(Debug, Clone)]
pub enum TestPatternMode {
    /// No test pattern mode is used. The camera device returns frames from
    /// the image sensor.
    Off = 0,
    /// Each pixel in [R, G_even, G_odd, B] is replaced by its respective
    /// color channel provided in test pattern data.
    /// \todo Add control for test pattern data.
    SolidColor = 1,
    /// All pixel data is replaced with an 8-bar color pattern. The vertical
    /// bars (left-to-right) are as follows; white, yellow, cyan, green,
    /// magenta, red, blue and black. Each bar should take up 1/8 of the
    /// sensor pixel array width. When this is not possible, the bar size
    /// should be rounded down to the nearest integer and the pattern can
    /// repeat on the right side. Each bar's height must always take up the
    /// full sensor pixel array height.
    ColorBars = 2,
    /// The test pattern is similar to TestPatternModeColorBars,
    /// except that each bar should start at its specified color at the top
    /// and fade to gray at the bottom. Furthermore each bar is further
    /// subdevided into a left and right half. The left half should have a
    /// smooth gradient, and the right half should have a quantized
    /// gradient. In particular, the right half's should consist of blocks
    /// of the same color for 1/16th active sensor pixel array width. The
    /// least significant bits in the quantized gradient should be copied
    /// from the most significant bits of the smooth gradient. The height of
    /// each bar should always be a multiple of 128. When this is not the
    /// case, the pattern should repeat at the bottom of the image.
    ColorBarsFadeToGray = 3,
    /// All pixel data is replaced by a pseudo-random sequence generated
    /// from a PN9 512-bit sequence (typically implemented in hardware with
    /// a linear feedback shift register). The generator should be reset at
    /// the beginning of each frame, and thus each subsequent raw frame with
    /// this test pattern should be exactly the same as the last.
    Pn9 = 4,
    /// The first custom test pattern. All custom patterns that are
    /// available only on this camera device are at least this numeric
    /// value. All of the custom test patterns will be static (that is the
    /// raw image must not vary from frame to frame).
    Custom1 = 256,
}

impl TryFrom<i32> for TestPatternMode {
    type Error = ControlValueError;

    fn try_from(value: i32) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(Self::Off),
1 => Ok(Self::SolidColor),
2 => Ok(Self::ColorBars),
3 => Ok(Self::ColorBarsFadeToGray),
4 => Ok(Self::Pn9),
256 => Ok(Self::Custom1),
            _ => Err(ControlValueError::InvalidData)
        }
    }
}

impl Into<i32> for TestPatternMode {
    fn into(self) -> i32 {
        self as _
    }
}

impl Control for TestPatternMode {
    const ID: u32 = ControlId::TestPatternMode as _;
    type T = i32;
}

